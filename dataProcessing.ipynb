{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "polyphonic-elevation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#libraries & dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#data normalizing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#imputation of missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "#visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worldwide-biodiversity",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was loaded. Time:  47.19129204750061\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "trainTransaction = pd.read_csv('/Users/mike/ieee-fraud-detection/train_transaction.csv')\n",
    "trainIdentity = pd.read_csv('/Users/mike/ieee-fraud-detection/train_identity.csv')\n",
    "testTransaction = pd.read_csv('/Users/mike/ieee-fraud-detection/test_transaction.csv')\n",
    "testIdentity = pd.read_csv('/Users/mike/ieee-fraud-detection/test_identity.csv')\n",
    "print('Data was loaded. Time: ', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "smooth-lexington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506691, 393)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 590540 entries, 0 to 590539\n",
      "Columns: 394 entries, TransactionID to V339\n",
      "dtypes: float64(376), int64(4), object(14)\n",
      "memory usage: 1.7+ GB\n",
      "Percentage of fraudulent transactions: 3.499000914417313\n"
     ]
    }
   ],
   "source": [
    "#Data preparation: checking the percentage of fraudulent transactions\n",
    "print(testTransaction.shape)\n",
    "trainTransaction.info()\n",
    "print('Percentage of fraudulent transactions:', len(trainTransaction.loc[trainTransaction.isFraud == 1]) * 100/len(trainTransaction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "appreciated-silence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='isFraud', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(trainTransaction.isFraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spread-scheduling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 394)\n",
      "(590540, 393)\n"
     ]
    }
   ],
   "source": [
    "#now it is crucial to remove 'isFraud' field, cause in several steps next the dataset would be divided into test/training sets\n",
    "y_train = trainTransaction['isFraud']\n",
    "print(trainTransaction.shape)\n",
    "trainTransaction = trainTransaction.drop(columns = ['isFraud'])\n",
    "print(trainTransaction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "golden-comment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionID  TransactionDT  TransactionAmt ProductCD  card1  card2  \\\n",
      "0        2987000          86400            68.5         W  13926    NaN   \n",
      "1        2987001          86401            29.0         W   2755  404.0   \n",
      "2        2987002          86469            59.0         W   4663  490.0   \n",
      "3        2987003          86499            50.0         W  18132  567.0   \n",
      "4        2987004          86506            50.0         H   4497  514.0   \n",
      "\n",
      "   card3       card4  card5   card6  ...  V330  V331  V332  V333 V334 V335  \\\n",
      "0  150.0    discover  142.0  credit  ...   NaN   NaN   NaN   NaN  NaN  NaN   \n",
      "1  150.0  mastercard  102.0  credit  ...   NaN   NaN   NaN   NaN  NaN  NaN   \n",
      "2  150.0        visa  166.0   debit  ...   NaN   NaN   NaN   NaN  NaN  NaN   \n",
      "3  150.0  mastercard  117.0   debit  ...   NaN   NaN   NaN   NaN  NaN  NaN   \n",
      "4  150.0  mastercard  102.0  credit  ...   0.0   0.0   0.0   0.0  0.0  0.0   \n",
      "\n",
      "   V336  V337  V338  V339  \n",
      "0   NaN   NaN   NaN   NaN  \n",
      "1   NaN   NaN   NaN   NaN  \n",
      "2   NaN   NaN   NaN   NaN  \n",
      "3   NaN   NaN   NaN   NaN  \n",
      "4   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 393 columns]\n",
      "   TransactionID  id_01     id_02  id_03  id_04  id_05  id_06  id_07  id_08  \\\n",
      "0        2987004    0.0   70787.0    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "1        2987008   -5.0   98945.0    NaN    NaN    0.0   -5.0    NaN    NaN   \n",
      "2        2987010   -5.0  191631.0    0.0    0.0    0.0    0.0    NaN    NaN   \n",
      "3        2987011   -5.0  221832.0    NaN    NaN    0.0   -6.0    NaN    NaN   \n",
      "4        2987016    0.0    7460.0    0.0    0.0    1.0    0.0    NaN    NaN   \n",
      "\n",
      "   id_09  ...                id_31  id_32      id_33           id_34  id_35  \\\n",
      "0    NaN  ...  samsung browser 6.2   32.0  2220x1080  match_status:2      T   \n",
      "1    NaN  ...   mobile safari 11.0   32.0   1334x750  match_status:1      T   \n",
      "2    0.0  ...          chrome 62.0    NaN        NaN             NaN      F   \n",
      "3    NaN  ...          chrome 62.0    NaN        NaN             NaN      F   \n",
      "4    0.0  ...          chrome 62.0   24.0   1280x800  match_status:2      T   \n",
      "\n",
      "  id_36 id_37  id_38  DeviceType                     DeviceInfo  \n",
      "0     F     T      T      mobile  SAMSUNG SM-G892A Build/NRD90M  \n",
      "1     F     F      T      mobile                     iOS Device  \n",
      "2     F     T      T     desktop                        Windows  \n",
      "3     F     T      T     desktop                            NaN  \n",
      "4     F     T      T     desktop                          MacOS  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "(144233, 41)\n",
      "Index(['TransactionID', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06',\n",
      "       'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14',\n",
      "       'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22',\n",
      "       'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30',\n",
      "       'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n",
      "       'DeviceType', 'DeviceInfo'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#smth should be done with NaN fields\n",
    "print(trainTransaction.head())\n",
    "print(trainIdentity.head())\n",
    "print(trainIdentity.shape)\n",
    "print(trainIdentity.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "academic-cardiff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TransactionID', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06',\n",
      "       'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14',\n",
      "       'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22',\n",
      "       'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30',\n",
      "       'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n",
      "       'DeviceType', 'DeviceInfo'],\n",
      "      dtype='object')\n",
      "(1097231, 393)\n",
      "(286140, 41)\n"
     ]
    }
   ],
   "source": [
    "#understanding some info about identity dataset\n",
    "#in somewhere next much more precious evaluation on id content\n",
    "#merging train/test data to normalize\n",
    "#print(trainTransaction.index)\n",
    "#print(trainIdentity.index)\n",
    "#print(trainIdentity.id_01.value_counts())\n",
    "#print(trainIdentity.id_07.value_counts())\n",
    "#print(trainIdentity.id_33.value_counts())\n",
    "#print(trainIdentity.DeviceType.value_counts())\n",
    "#print(trainIdentity.DeviceInfo.value_counts())\n",
    "testIdentity.columns = ['TransactionID', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08',\n",
    "       'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16',\n",
    "       'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24',\n",
    "       'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32',\n",
    "       'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType',\n",
    "       'DeviceInfo']\n",
    "print(testIdentity.columns)\n",
    "trainTransaction = pd.concat([trainTransaction, testTransaction])\n",
    "trainIdentity = pd.concat([trainIdentity, testIdentity], axis = 0)\n",
    "print(trainTransaction.shape)\n",
    "print(trainIdentity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ongoing-canadian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity dataset:\n",
      "\n",
      "Quantity of categorical columns:  17\n",
      "Quantity of numerical columns:  24\n",
      "['TransactionID', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_13', 'id_14', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_24', 'id_25', 'id_26', 'id_32']\n",
      "['id_12', 'id_15', 'id_16', 'id_23', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo']\n",
      "\n",
      "Transaction dataset:\n",
      "\n",
      "Quantity of categorical columns:  14\n",
      "Quantity of numerical columns:  379\n"
     ]
    }
   ],
   "source": [
    "#generating separate lists for numerical and categorical data\n",
    "print('Identity dataset:\\n')\n",
    "helpCat = (trainIdentity.dtypes == 'object')\n",
    "categoricalColumnsId = list(helpCat[helpCat].index)\n",
    "print('Quantity of categorical columns: ', len(categoricalColumnsId))\n",
    "#print(categoricalColumnsId)\n",
    "helpNum = (trainIdentity.dtypes != 'object')\n",
    "numericalColumnsId = list(helpNum[helpNum].index)\n",
    "print('Quantity of numerical columns: ', len(numericalColumnsId))\n",
    "print(numericalColumnsId)\n",
    "print(categoricalColumnsId)\n",
    "#print(numericalColumnsId)\n",
    "print('\\nTransaction dataset:\\n')\n",
    "helpCat = (trainTransaction.dtypes == 'object')\n",
    "categoricalColumnsTS = list(helpCat[helpCat].index)\n",
    "print('Quantity of categorical columns: ', len(categoricalColumnsTS))\n",
    "#print(categoricalColumnsTS)\n",
    "helpNum = (trainTransaction.dtypes != 'object')\n",
    "numericalColumnsTS = list(helpNum[helpNum].index)\n",
    "print('Quantity of numerical columns: ', len(numericalColumnsTS))\n",
    "#print(numericalColumnsTS)\n",
    "#somewhere next datasets should be merged by TRANSACTIONID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "desperate-market",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low 11\n",
      "medium 4\n",
      "many 2\n"
     ]
    }
   ],
   "source": [
    "#СДЕЛАТЬ ГИСТОГРАММУ!\n",
    "#starting with identity dataset\n",
    "#trying to understand id fields, removing with high perscentage of NaN\n",
    "#categorical Identity\n",
    "featuresList = []\n",
    "percentageList = []\n",
    "lowMissingCatID = []\n",
    "mediumMissingCatID = []\n",
    "manyMissingCatID = []\n",
    "for i in categoricalColumnsId:\n",
    "    #print(trainIdentity[i].value_counts())\n",
    "    percentage = trainIdentity[i].isnull().sum()*100/len(trainIdentity[i])\n",
    "    featuresList.append(i)\n",
    "    percentageList.append(percentage)\n",
    "    if percentage < 15:\n",
    "        lowMissingCatID.append(i)\n",
    "    elif percentage >= 15 and percentage < 60:\n",
    "        mediumMissingCatID.append(i)\n",
    "    else:\n",
    "        manyMissingCatID.append(i)\n",
    "    #print(i, 'percentage of missing values: ', percentage)\n",
    "\n",
    "print('low', len(lowMissingCatID))\n",
    "print('medium', len(mediumMissingCatID))\n",
    "print('many', len(manyMissingCatID))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "level-links",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low 10\n",
      "medium 6\n",
      "many 8\n"
     ]
    }
   ],
   "source": [
    "#numerical Identity\n",
    "lowMissingNumID = []\n",
    "mediumMissingNumID = []\n",
    "manyMissingNumID = []\n",
    "for i in numericalColumnsId:\n",
    "    #print(trainIdentity[i].value_counts())\n",
    "    percentage = trainIdentity[i].isnull().sum()*100/len(trainIdentity[i])\n",
    "    featuresList.append(i)\n",
    "    percentageList.append(percentage)\n",
    "    if percentage < 15:\n",
    "        lowMissingNumID.append(i)\n",
    "    elif percentage >= 15 and percentage < 60:\n",
    "        mediumMissingNumID.append(i)\n",
    "    else:\n",
    "        manyMissingNumID.append(i)\n",
    "print('low', len(lowMissingNumID))\n",
    "print('medium', len(mediumMissingNumID))\n",
    "print('many', len(manyMissingNumID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adapted-flight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low 4\n",
      "medium 8\n",
      "many 2\n"
     ]
    }
   ],
   "source": [
    "#categorical transaction\n",
    "lowMissingCatTS = []\n",
    "mediumMissingCatTS = []\n",
    "manyMissingCatTS = []\n",
    "for i in categoricalColumnsTS:\n",
    "    #print(trainIdentity[i].value_counts())\n",
    "    percentage = trainTransaction[i].isnull().sum()*100/len(trainTransaction[i])\n",
    "    if percentage < 15:\n",
    "        lowMissingCatTS.append(i)\n",
    "    elif percentage >= 15 and percentage < 60:\n",
    "        mediumMissingCatTS.append(i)\n",
    "    else:\n",
    "        manyMissingCatTS.append(i)\n",
    "        \n",
    "print('low', len(lowMissingCatTS))\n",
    "print('medium', len(mediumMissingCatTS))\n",
    "print('many', len(manyMissingCatTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "later-sunset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low 177\n",
      "medium 35\n",
      "many 167\n"
     ]
    }
   ],
   "source": [
    "#numerical Transaction\n",
    "lowMissingNumTS = []\n",
    "mediumMissingNumTS = []\n",
    "manyMissingNumTS = []\n",
    "for i in numericalColumnsTS:\n",
    "    #print(trainIdentity[i].value_counts())\n",
    "    percentage = trainTransaction[i].isnull().sum()*100/len(trainTransaction[i])\n",
    "    if percentage < 15:\n",
    "        lowMissingNumTS.append(i)\n",
    "    elif percentage >= 15 and percentage < 60:\n",
    "        mediumMissingNumTS.append(i)\n",
    "    else:\n",
    "        manyMissingNumTS.append(i)\n",
    "        \n",
    "print('low', len(lowMissingNumTS))\n",
    "print('medium', len(mediumMissingNumTS))\n",
    "print('many', len(manyMissingNumTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "suspended-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "#написать про промежуточный итог\n",
    "#на этом этапе создать таблицу со сравнением, а после написать о действиях с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "existing-municipality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping in transactions numerical:  (1097231, 393)\n",
      "After dropping in transactions numerical:  (1097231, 226)\n",
      "Before dropping in identity numerical:  (286140, 41)\n",
      "After dropping in identity numerical:  (286140, 33)\n",
      "Before dropping in identity categorical:  (286140, 33)\n",
      "After dropping in identity categorical:  (286140, 31)\n",
      "Before dropping in transaction categorical:  (1097231, 226)\n",
      "After dropping in transaction categorical:  (1097231, 224)\n"
     ]
    }
   ],
   "source": [
    "#WORKING with numerical data in identity and transactions\n",
    "#dropping fields with 'many' missing, shape value is used as flag\n",
    "print('Before dropping in transactions numerical: ', trainTransaction.shape)\n",
    "trainTransaction = trainTransaction.drop(columns = manyMissingNumTS)\n",
    "print('After dropping in transactions numerical: ', trainTransaction.shape)\n",
    "print('Before dropping in identity numerical: ', trainIdentity.shape)\n",
    "trainIdentity = trainIdentity.drop(columns = manyMissingNumID)\n",
    "print('After dropping in identity numerical: ', trainIdentity.shape)\n",
    "print('Before dropping in identity categorical: ', trainIdentity.shape)\n",
    "trainIdentity = trainIdentity.drop(columns = manyMissingCatID)\n",
    "print('After dropping in identity categorical: ', trainIdentity.shape)\n",
    "print('Before dropping in transaction categorical: ', trainTransaction.shape)\n",
    "trainTransaction = trainTransaction.drop(columns = manyMissingCatTS)\n",
    "print('After dropping in transaction categorical: ', trainTransaction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "minor-clark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values before imputation: \n",
      "TransactionID         0\n",
      "TransactionDT         0\n",
      "TransactionAmt        0\n",
      "card1                 0\n",
      "card2             17587\n",
      "                  ...  \n",
      "V317                 15\n",
      "V318                 15\n",
      "V319                 15\n",
      "V320                 15\n",
      "V321                 15\n",
      "Length: 177, dtype: int64\n",
      "Values after imputation: \n",
      "TransactionID     0\n",
      "TransactionDT     0\n",
      "TransactionAmt    0\n",
      "card1             0\n",
      "card2             0\n",
      "                 ..\n",
      "V317              0\n",
      "V318              0\n",
      "V319              0\n",
      "V320              0\n",
      "V321              0\n",
      "Length: 177, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#imputation of low missing numerical data\n",
    "#transaction\n",
    "print('Values before imputation: ')\n",
    "print(trainTransaction[lowMissingNumTS].isnull().sum())\n",
    "tsLImputation = SimpleImputer(strategy = 'mean')\n",
    "tsLImputation.fit(trainTransaction[lowMissingNumTS])\n",
    "trainTransaction[lowMissingNumTS] = tsLImputation.transform(trainTransaction[lowMissingNumTS])\n",
    "print('Values after imputation: ')\n",
    "print(trainTransaction[lowMissingNumTS].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "human-allowance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values before imputation: \n",
      "TransactionID        0\n",
      "id_01                0\n",
      "id_02             8292\n",
      "id_05            14525\n",
      "id_06            14525\n",
      "id_11             8384\n",
      "id_13            28534\n",
      "id_17            10805\n",
      "id_19            10916\n",
      "id_20            11246\n",
      "dtype: int64\n",
      "Values after imputation: \n",
      "TransactionID    0\n",
      "id_01            0\n",
      "id_02            0\n",
      "id_05            0\n",
      "id_06            0\n",
      "id_11            0\n",
      "id_13            0\n",
      "id_17            0\n",
      "id_19            0\n",
      "id_20            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#imputation of low missing numerical data\n",
    "#identity\n",
    "print('Values before imputation: ')\n",
    "print(trainIdentity[lowMissingNumID].isnull().sum())\n",
    "idImputation = SimpleImputer(strategy = 'mean')\n",
    "idImputation.fit(trainIdentity[lowMissingNumID])\n",
    "trainIdentity[lowMissingNumID] = idImputation.transform(trainIdentity[lowMissingNumID])\n",
    "print('Values after imputation: ')\n",
    "print(trainIdentity[lowMissingNumID].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "theoretical-dictionary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values before imputation: \n",
      "dist1    643488\n",
      "D2       515566\n",
      "D3       466020\n",
      "D4       245773\n",
      "D5       534216\n",
      "D11      455805\n",
      "V1       455805\n",
      "V2       455805\n",
      "V3       455805\n",
      "V4       455805\n",
      "V5       455805\n",
      "V6       455805\n",
      "V7       455805\n",
      "V8       455805\n",
      "V9       455805\n",
      "V10      455805\n",
      "V11      455805\n",
      "V35      245823\n",
      "V36      245823\n",
      "V37      245823\n",
      "V38      245823\n",
      "V39      245823\n",
      "V40      245823\n",
      "V41      245823\n",
      "V42      245823\n",
      "V43      245823\n",
      "V44      245823\n",
      "V45      245823\n",
      "V46      245823\n",
      "V47      245823\n",
      "V48      245823\n",
      "V49      245823\n",
      "V50      245823\n",
      "V51      245823\n",
      "V52      245823\n",
      "dtype: int64\n",
      "Values after imputation: \n",
      "dist1    0\n",
      "D2       0\n",
      "D3       0\n",
      "D4       0\n",
      "D5       0\n",
      "D11      0\n",
      "V1       0\n",
      "V2       0\n",
      "V3       0\n",
      "V4       0\n",
      "V5       0\n",
      "V6       0\n",
      "V7       0\n",
      "V8       0\n",
      "V9       0\n",
      "V10      0\n",
      "V11      0\n",
      "V35      0\n",
      "V36      0\n",
      "V37      0\n",
      "V38      0\n",
      "V39      0\n",
      "V40      0\n",
      "V41      0\n",
      "V42      0\n",
      "V43      0\n",
      "V44      0\n",
      "V45      0\n",
      "V46      0\n",
      "V47      0\n",
      "V48      0\n",
      "V49      0\n",
      "V50      0\n",
      "V51      0\n",
      "V52      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#imputation of medium missing numerical data\n",
    "#transaction\n",
    "print('Values before imputation: ')\n",
    "print(trainTransaction[mediumMissingNumTS].isnull().sum())\n",
    "tsLImputation = SimpleImputer(strategy = 'median')\n",
    "tsLImputation.fit(trainTransaction[mediumMissingNumTS])\n",
    "trainTransaction[mediumMissingNumTS] = tsLImputation.transform(trainTransaction[mediumMissingNumTS])\n",
    "print('Values after imputation: ')\n",
    "print(trainTransaction[mediumMissingNumTS].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "duplicate-brave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values before imputation: \n",
      "id_03    153335\n",
      "id_04    153335\n",
      "id_09    136876\n",
      "id_10    136876\n",
      "id_14    134739\n",
      "id_32    137883\n",
      "dtype: int64\n",
      "Values after imputation: \n",
      "id_03    0\n",
      "id_04    0\n",
      "id_09    0\n",
      "id_10    0\n",
      "id_14    0\n",
      "id_32    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#imputation of medium missing numerical data\n",
    "#identity\n",
    "print('Values before imputation: ')\n",
    "print(trainIdentity[mediumMissingNumID].isnull().sum())\n",
    "idImputation = SimpleImputer(strategy = 'median')\n",
    "idImputation.fit(trainIdentity[mediumMissingNumID])\n",
    "trainIdentity[mediumMissingNumID] = idImputation.transform(trainIdentity[mediumMissingNumID])\n",
    "print('Values after imputation: ')\n",
    "print(trainIdentity[mediumMissingNumID].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "victorian-animation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1097231 entries, 0 to 506690\n",
      "Columns: 224 entries, TransactionID to V321\n",
      "dtypes: float64(212), object(12)\n",
      "memory usage: 1.8+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 286140 entries, 0 to 141906\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   TransactionID  286140 non-null  float64\n",
      " 1   id_01          286140 non-null  float64\n",
      " 2   id_02          286140 non-null  float64\n",
      " 3   id_03          286140 non-null  float64\n",
      " 4   id_04          286140 non-null  float64\n",
      " 5   id_05          286140 non-null  float64\n",
      " 6   id_06          286140 non-null  float64\n",
      " 7   id_09          286140 non-null  float64\n",
      " 8   id_10          286140 non-null  float64\n",
      " 9   id_11          286140 non-null  float64\n",
      " 10  id_12          286140 non-null  object \n",
      " 11  id_13          286140 non-null  float64\n",
      " 12  id_14          286140 non-null  float64\n",
      " 13  id_15          277962 non-null  object \n",
      " 14  id_16          255087 non-null  object \n",
      " 15  id_17          286140 non-null  float64\n",
      " 16  id_19          286140 non-null  float64\n",
      " 17  id_20          286140 non-null  float64\n",
      " 18  id_28          277756 non-null  object \n",
      " 19  id_29          277756 non-null  object \n",
      " 20  id_30          148224 non-null  object \n",
      " 21  id_31          276907 non-null  object \n",
      " 22  id_32          286140 non-null  float64\n",
      " 23  id_33          143960 non-null  object \n",
      " 24  id_34          149980 non-null  object \n",
      " 25  id_35          277962 non-null  object \n",
      " 26  id_36          277962 non-null  object \n",
      " 27  id_37          277962 non-null  object \n",
      " 28  id_38          277962 non-null  object \n",
      " 29  DeviceType     277741 non-null  object \n",
      " 30  DeviceInfo     233723 non-null  object \n",
      "dtypes: float64(16), object(15)\n",
      "memory usage: 69.9+ MB\n",
      "None\n",
      "datatype summary for transaction dataset is:\n",
      "\n",
      "Object:  12\n",
      "Int:  0\n",
      "Float:  212\n",
      "datatype summary for identity dataset is:\n",
      "\n",
      "Object:  15\n",
      "Int:  0\n",
      "Float:  16\n"
     ]
    }
   ],
   "source": [
    "#memory usage reduction\n",
    "print(trainTransaction.info())\n",
    "print(trainIdentity.info())\n",
    "#getting info about columns data type\n",
    "objectCount = 0\n",
    "intCount = 0\n",
    "floatCount = 0\n",
    "for i in trainTransaction.columns:\n",
    "    if trainTransaction[i].dtype == 'object':\n",
    "        objectCount += 1\n",
    "    elif trainTransaction[i].dtype == 'int':\n",
    "        intCount += 1\n",
    "    else:\n",
    "        floatCount += 1\n",
    "print('datatype summary for transaction dataset is:\\n')\n",
    "print('Object: ', objectCount)\n",
    "print('Int: ', intCount)\n",
    "print('Float: ', floatCount)\n",
    "\n",
    "if len(trainTransaction.columns) != (objectCount + intCount + floatCount):\n",
    "    print('ERROR!')\n",
    "objectCount = 0\n",
    "intCount = 0\n",
    "floatCount = 0\n",
    "for i in trainIdentity.columns:\n",
    "    if trainIdentity[i].dtype == 'object':\n",
    "        objectCount += 1\n",
    "    elif trainIdentity[i].dtype == 'int':\n",
    "        intCount += 1\n",
    "    else:\n",
    "        floatCount += 1\n",
    "print('datatype summary for identity dataset is:\\n')\n",
    "print('Object: ', objectCount)\n",
    "print('Int: ', intCount)\n",
    "print('Float: ', floatCount)\n",
    "\n",
    "if len(trainIdentity.columns) != (objectCount + intCount + floatCount):\n",
    "    print('ERROR!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "driving-automation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionID  TransactionDT  TransactionAmt ProductCD    card1  \\\n",
      "0      2987000.0        86400.0            68.5         W  13926.0   \n",
      "1      2987001.0        86401.0            29.0         W   2755.0   \n",
      "2      2987002.0        86469.0            59.0         W   4663.0   \n",
      "3      2987003.0        86499.0            50.0         W  18132.0   \n",
      "4      2987004.0        86506.0            50.0         H   4497.0   \n",
      "\n",
      "        card2  card3       card4  card5   card6  ...   V312  V313  V314 V315  \\\n",
      "0  363.099769  150.0    discover  142.0  credit  ...    0.0   0.0   0.0  0.0   \n",
      "1  404.000000  150.0  mastercard  102.0  credit  ...    0.0   0.0   0.0  0.0   \n",
      "2  490.000000  150.0        visa  166.0   debit  ...    0.0   0.0   0.0  0.0   \n",
      "3  567.000000  150.0  mastercard  117.0   debit  ...  135.0   0.0   0.0  0.0   \n",
      "4  514.000000  150.0  mastercard  102.0  credit  ...    0.0   0.0   0.0  0.0   \n",
      "\n",
      "   V316    V317   V318  V319  V320  V321  \n",
      "0   0.0   117.0    0.0   0.0   0.0   0.0  \n",
      "1   0.0     0.0    0.0   0.0   0.0   0.0  \n",
      "2   0.0     0.0    0.0   0.0   0.0   0.0  \n",
      "3  50.0  1404.0  790.0   0.0   0.0   0.0  \n",
      "4   0.0     0.0    0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 224 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1097231 entries, 0 to 506690\n",
      "Columns: 224 entries, TransactionID to V321\n",
      "dtypes: float16(188), float32(24), object(12)\n",
      "memory usage: 602.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#as it can be seen, the 'heaviest' datatype - float64\n",
    "#trying to shrink it\n",
    "print(trainTransaction.head())\n",
    "def columnsToShrink(columnsList, data):\n",
    "    convertInt8 = []\n",
    "    convertInt16 = []\n",
    "    convertInt32 = []\n",
    "    convertFloat16 = []\n",
    "    convertFloat32 = []\n",
    "    for col in columnsList:\n",
    "        #print(data[col])\n",
    "        if data[col].dtype in ['int', 'int8', 'int32', 'int64']:\n",
    "            descColumn = data[col].describe()\n",
    "            minimum = descColumn[3]\n",
    "            maximum = descColumn[7]\n",
    "            difference = abs(maximum - minimum)\n",
    "\n",
    "            if difference < 255:\n",
    "                convertInt8.append(col)\n",
    "            elif difference < 65535:\n",
    "                convertInt16.append(col)\n",
    "            elif difference < 4294967295:\n",
    "                convertInt32.append(col)  \n",
    "        elif data[col].dtype in ['float', 'float16', 'float32', 'float64']:\n",
    "            descColumn = data[col].describe()\n",
    "            minimum = descColumn[3]\n",
    "            maximum = descColumn[7]\n",
    "            difference = abs(maximum - minimum)\n",
    "            if difference < 65535:\n",
    "                convertFloat16.append(col)\n",
    "            elif difference < 4294967295:\n",
    "                convertFloat32.append(col)\n",
    "    return convertFloat16, convertFloat32\n",
    "\n",
    "helpNum = (trainTransaction.dtypes != 'object')\n",
    "numericalColumnsTS = list(helpNum[helpNum].index)\n",
    "float16TS, float32TS = columnsToShrink(numericalColumnsTS, trainTransaction)\n",
    "for col in float16TS:\n",
    "    trainTransaction[col] = trainTransaction[col].astype('float16')\n",
    "for col in float32TS:\n",
    "    trainTransaction[col] = trainTransaction[col].astype('float32')\n",
    "print(trainTransaction.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "emotional-lemon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 286140 entries, 0 to 141906\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   TransactionID  286140 non-null  float32\n",
      " 1   id_01          286140 non-null  float16\n",
      " 2   id_02          286140 non-null  float32\n",
      " 3   id_03          286140 non-null  float16\n",
      " 4   id_04          286140 non-null  float16\n",
      " 5   id_05          286140 non-null  float16\n",
      " 6   id_06          286140 non-null  float16\n",
      " 7   id_09          286140 non-null  float16\n",
      " 8   id_10          286140 non-null  float16\n",
      " 9   id_11          286140 non-null  float16\n",
      " 10  id_12          286140 non-null  object \n",
      " 11  id_13          286140 non-null  float16\n",
      " 12  id_14          286140 non-null  float16\n",
      " 13  id_15          277962 non-null  object \n",
      " 14  id_16          255087 non-null  object \n",
      " 15  id_17          286140 non-null  float16\n",
      " 16  id_19          286140 non-null  float16\n",
      " 17  id_20          286140 non-null  float16\n",
      " 18  id_28          277756 non-null  object \n",
      " 19  id_29          277756 non-null  object \n",
      " 20  id_30          148224 non-null  object \n",
      " 21  id_31          276907 non-null  object \n",
      " 22  id_32          286140 non-null  float16\n",
      " 23  id_33          143960 non-null  object \n",
      " 24  id_34          149980 non-null  object \n",
      " 25  id_35          277962 non-null  object \n",
      " 26  id_36          277962 non-null  object \n",
      " 27  id_37          277962 non-null  object \n",
      " 28  id_38          277962 non-null  object \n",
      " 29  DeviceType     277741 non-null  object \n",
      " 30  DeviceInfo     233723 non-null  object \n",
      "dtypes: float16(14), float32(2), object(15)\n",
      "memory usage: 44.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "helpNum = (trainIdentity.dtypes != 'object')\n",
    "numericalColumnsId = list(helpNum[helpNum].index)\n",
    "float16Id, float32Id = columnsToShrink(numericalColumnsId, trainIdentity)\n",
    "for col in float16Id:\n",
    "    trainIdentity[col] = trainIdentity[col].astype('float16')\n",
    "for col in float32Id:\n",
    "    trainIdentity[col] = trainIdentity[col].astype('float32')\n",
    "print(trainIdentity.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "partial-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing values in the categorical data\n",
    "#firstly, cardinality of each categorical faeture should be counted\n",
    "helpCat = (trainIdentity.dtypes == 'object')\n",
    "categoricalColumnsId = list(helpCat[helpCat].index)\n",
    "helpCat = (trainTransaction.dtypes == 'object')\n",
    "categoricalColumnsTS = list(helpCat[helpCat].index)\n",
    "#for col in categoricalColumnsTS:\n",
    "    #print(col, trainTransaction[col].nunique())\n",
    "#analogicaly with numerical data, I'm trying to divide categorical data into low/high cardinality\n",
    "lowCardinalityTS = [\"ProductCD\", \"card4\", \"card6\", \"M1\", \"M2\", \"M3\", \"M4\", \"M6\", \"M7\", \"M8\", \"M9\"]\n",
    "highCardinalityTS = [\"P_emaildomain\"]\n",
    "for col in categoricalColumnsTS:\n",
    "    columnMode = trainTransaction[col].mode()[0]\n",
    "    trainTransaction[col].fillna(columnMode, inplace = True)\n",
    "    #print(col, columnMode)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cardiac-timothy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High cardinality data before encoding:         P_emaildomain\n",
      "0          gmail.com\n",
      "1          gmail.com\n",
      "2        outlook.com\n",
      "3          yahoo.com\n",
      "4          gmail.com\n",
      "...              ...\n",
      "506686     gmail.com\n",
      "506687   hotmail.com\n",
      "506688   hotmail.com\n",
      "506689   hotmail.com\n",
      "506690   hotmail.com\n",
      "\n",
      "[1097231 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High cardinality data after encoding:          P_emaildomain\n",
      "0                  16\n",
      "1                  16\n",
      "2                  35\n",
      "3                  54\n",
      "4                  16\n",
      "...               ...\n",
      "506686             16\n",
      "506687             19\n",
      "506688             19\n",
      "506689             19\n",
      "506690             19\n",
      "\n",
      "[1097231 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#label-encoding data with high cardinality\n",
    "labEncode = LabelEncoder()\n",
    "print('High cardinality data before encoding: ', trainTransaction[highCardinalityTS])\n",
    "trainTransaction[highCardinalityTS] = labEncode.fit_transform(trainTransaction[highCardinalityTS])\n",
    "print('High cardinality data after encoding: ', trainTransaction[highCardinalityTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "compressed-thailand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_12 NotFound\n",
      "id_15 Found\n",
      "id_16 Found\n",
      "id_28 Found\n",
      "id_29 Found\n",
      "id_30 Windows 10\n",
      "id_31 mobile safari 11.0\n",
      "id_33 1920x1080\n",
      "id_34 match_status:2\n",
      "id_35 T\n",
      "id_36 F\n",
      "id_37 T\n",
      "id_38 F\n",
      "DeviceType desktop\n",
      "DeviceInfo Windows\n"
     ]
    }
   ],
   "source": [
    "#for col in categoricalColumnsId:\n",
    "    #print(col, trainIdentity[col].nunique())\n",
    "lowCardinalityID = [\"id_12\", \"id_15\", \"id_16\", \"id_28\", \"id_29\", \"id_34\", \"id_35\", \"id_36\", \"id_37\", \"id_38\", \"DeviceType\"]\n",
    "highCardinalityID = [\"id_30\", \"id_31\", \"id_33\", \"DeviceInfo\"]\n",
    "#print(lowCardinalityID)\n",
    "#print(highCardinalityID)\n",
    "for col in categoricalColumnsId:\n",
    "    columnMode = trainIdentity[col].mode()[0]\n",
    "    trainIdentity[col].fillna(columnMode, inplace = True)\n",
    "    print(col, columnMode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cardiac-vertical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High cardinality data before encoding:                     id_30                    id_31      id_33  \\\n",
      "0            Android 7.0      samsung browser 6.2  2220x1080   \n",
      "1             iOS 11.1.2       mobile safari 11.0   1334x750   \n",
      "2             Windows 10              chrome 62.0  1920x1080   \n",
      "3             Windows 10              chrome 62.0  1920x1080   \n",
      "4       Mac OS X 10_11_6              chrome 62.0   1280x800   \n",
      "...                  ...                      ...        ...   \n",
      "141902        Windows 10  chrome 71.0 for android  1920x1080   \n",
      "141903        Windows 10  chrome 71.0 for android  1920x1080   \n",
      "141904        iOS 10.3.3       mobile safari 10.0   1334x750   \n",
      "141905        Windows 10  chrome 43.0 for android  1920x1080   \n",
      "141906        Windows 10      samsung browser 8.2  1920x1080   \n",
      "\n",
      "                           DeviceInfo  \n",
      "0       SAMSUNG SM-G892A Build/NRD90M  \n",
      "1                          iOS Device  \n",
      "2                             Windows  \n",
      "3                             Windows  \n",
      "4                               MacOS  \n",
      "...                               ...  \n",
      "141902                       SM-J700M  \n",
      "141903                       SM-J320M  \n",
      "141904                     iOS Device  \n",
      "141905    ALE-L23 Build/HuaweiALE-L23  \n",
      "141906                        SAMSUNG  \n",
      "\n",
      "[286140 rows x 4 columns]\n",
      "High cardinality data after encoding:          id_30  id_31  id_33  DeviceInfo\n",
      "0           7    161    268        1565\n",
      "1          70    130     80        2693\n",
      "2          49     46    216        2526\n",
      "3          49     46    216        2526\n",
      "4          26     46     68        1170\n",
      "...       ...    ...    ...         ...\n",
      "141902     49     74    216        2165\n",
      "141903     49     74    216        2106\n",
      "141904     63    129     80        2693\n",
      "141905     49     22    216         141\n",
      "141906     49    166    216        1529\n",
      "\n",
      "[286140 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#label-encoding data with high cardinality\n",
    "labEncode = LabelEncoder()\n",
    "print('High cardinality data before encoding: ', trainIdentity[highCardinalityID])\n",
    "for col in highCardinalityID:\n",
    "    trainIdentity[col] = labEncode.fit_transform(trainIdentity[col])\n",
    "print('High cardinality data after encoding: ', trainIdentity[highCardinalityID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "civilian-leader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1097231 entries, 0 to 506690\n",
      "Columns: 224 entries, TransactionID to V321\n",
      "dtypes: float16(188), float32(24), int64(1), object(11)\n",
      "memory usage: 602.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(trainTransaction.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "proof-apparel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehot-encoding\n",
    "encodedLowCardinalityDataTS = pd.get_dummies(trainTransaction[lowCardinalityTS], dummy_na = False)\n",
    "trainTransaction.drop(columns = lowCardinalityTS, inplace = True)\n",
    "encodedLowCardinalityDataID = pd.get_dummies(trainIdentity[lowCardinalityID], dummy_na = False)\n",
    "trainIdentity.drop(columns = lowCardinalityID, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "charitable-covering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 286140 entries, 0 to 141906\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   TransactionID  286140 non-null  float32\n",
      " 1   id_01          286140 non-null  float16\n",
      " 2   id_02          286140 non-null  float32\n",
      " 3   id_03          286140 non-null  float16\n",
      " 4   id_04          286140 non-null  float16\n",
      " 5   id_05          286140 non-null  float16\n",
      " 6   id_06          286140 non-null  float16\n",
      " 7   id_09          286140 non-null  float16\n",
      " 8   id_10          286140 non-null  float16\n",
      " 9   id_11          286140 non-null  float16\n",
      " 10  id_13          286140 non-null  float16\n",
      " 11  id_14          286140 non-null  float16\n",
      " 12  id_17          286140 non-null  float16\n",
      " 13  id_19          286140 non-null  float16\n",
      " 14  id_20          286140 non-null  float16\n",
      " 15  id_30          286140 non-null  int64  \n",
      " 16  id_31          286140 non-null  int64  \n",
      " 17  id_32          286140 non-null  float16\n",
      " 18  id_33          286140 non-null  int64  \n",
      " 19  DeviceInfo     286140 non-null  int64  \n",
      "dtypes: float16(14), float32(2), int64(4)\n",
      "memory usage: 20.7 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 286140 entries, 0 to 141906\n",
      "Data columns (total 25 columns):\n",
      " #   Column                 Non-Null Count   Dtype\n",
      "---  ------                 --------------   -----\n",
      " 0   id_12_Found            286140 non-null  uint8\n",
      " 1   id_12_NotFound         286140 non-null  uint8\n",
      " 2   id_15_Found            286140 non-null  uint8\n",
      " 3   id_15_New              286140 non-null  uint8\n",
      " 4   id_15_Unknown          286140 non-null  uint8\n",
      " 5   id_16_Found            286140 non-null  uint8\n",
      " 6   id_16_NotFound         286140 non-null  uint8\n",
      " 7   id_28_Found            286140 non-null  uint8\n",
      " 8   id_28_New              286140 non-null  uint8\n",
      " 9   id_29_Found            286140 non-null  uint8\n",
      " 10  id_29_NotFound         286140 non-null  uint8\n",
      " 11  id_34_match_status:-1  286140 non-null  uint8\n",
      " 12  id_34_match_status:0   286140 non-null  uint8\n",
      " 13  id_34_match_status:1   286140 non-null  uint8\n",
      " 14  id_34_match_status:2   286140 non-null  uint8\n",
      " 15  id_35_F                286140 non-null  uint8\n",
      " 16  id_35_T                286140 non-null  uint8\n",
      " 17  id_36_F                286140 non-null  uint8\n",
      " 18  id_36_T                286140 non-null  uint8\n",
      " 19  id_37_F                286140 non-null  uint8\n",
      " 20  id_37_T                286140 non-null  uint8\n",
      " 21  id_38_F                286140 non-null  uint8\n",
      " 22  id_38_T                286140 non-null  uint8\n",
      " 23  DeviceType_desktop     286140 non-null  uint8\n",
      " 24  DeviceType_mobile      286140 non-null  uint8\n",
      "dtypes: uint8(25)\n",
      "memory usage: 9.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(trainIdentity.info())\n",
    "print(encodedLowCardinalityDataID.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "persistent-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTransactionData = pd.concat([trainTransaction, encodedLowCardinalityDataTS], axis = 1)\n",
    "trainIdentityData = pd.concat([trainIdentity, encodedLowCardinalityDataID], axis = 1)\n",
    "testTransactionData = trainTransactionData.iloc[590540:]\n",
    "trainTransactionData = trainTransactionData.iloc[0:590540]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "massive-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDataSet = pd.merge(left = trainTransactionData, right = trainIdentityData, on = \"TransactionID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "accomplished-possession",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 286140 entries, 0 to 141906\n",
      "Data columns (total 45 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   TransactionID          286140 non-null  float32\n",
      " 1   id_01                  286140 non-null  float16\n",
      " 2   id_02                  286140 non-null  float32\n",
      " 3   id_03                  286140 non-null  float16\n",
      " 4   id_04                  286140 non-null  float16\n",
      " 5   id_05                  286140 non-null  float16\n",
      " 6   id_06                  286140 non-null  float16\n",
      " 7   id_09                  286140 non-null  float16\n",
      " 8   id_10                  286140 non-null  float16\n",
      " 9   id_11                  286140 non-null  float16\n",
      " 10  id_13                  286140 non-null  float16\n",
      " 11  id_14                  286140 non-null  float16\n",
      " 12  id_17                  286140 non-null  float16\n",
      " 13  id_19                  286140 non-null  float16\n",
      " 14  id_20                  286140 non-null  float16\n",
      " 15  id_30                  286140 non-null  int64  \n",
      " 16  id_31                  286140 non-null  int64  \n",
      " 17  id_32                  286140 non-null  float16\n",
      " 18  id_33                  286140 non-null  int64  \n",
      " 19  DeviceInfo             286140 non-null  int64  \n",
      " 20  id_12_Found            286140 non-null  uint8  \n",
      " 21  id_12_NotFound         286140 non-null  uint8  \n",
      " 22  id_15_Found            286140 non-null  uint8  \n",
      " 23  id_15_New              286140 non-null  uint8  \n",
      " 24  id_15_Unknown          286140 non-null  uint8  \n",
      " 25  id_16_Found            286140 non-null  uint8  \n",
      " 26  id_16_NotFound         286140 non-null  uint8  \n",
      " 27  id_28_Found            286140 non-null  uint8  \n",
      " 28  id_28_New              286140 non-null  uint8  \n",
      " 29  id_29_Found            286140 non-null  uint8  \n",
      " 30  id_29_NotFound         286140 non-null  uint8  \n",
      " 31  id_34_match_status:-1  286140 non-null  uint8  \n",
      " 32  id_34_match_status:0   286140 non-null  uint8  \n",
      " 33  id_34_match_status:1   286140 non-null  uint8  \n",
      " 34  id_34_match_status:2   286140 non-null  uint8  \n",
      " 35  id_35_F                286140 non-null  uint8  \n",
      " 36  id_35_T                286140 non-null  uint8  \n",
      " 37  id_36_F                286140 non-null  uint8  \n",
      " 38  id_36_T                286140 non-null  uint8  \n",
      " 39  id_37_F                286140 non-null  uint8  \n",
      " 40  id_37_T                286140 non-null  uint8  \n",
      " 41  id_38_F                286140 non-null  uint8  \n",
      " 42  id_38_T                286140 non-null  uint8  \n",
      " 43  DeviceType_desktop     286140 non-null  uint8  \n",
      " 44  DeviceType_mobile      286140 non-null  uint8  \n",
      "dtypes: float16(14), float32(2), int64(4), uint8(25)\n",
      "memory usage: 27.6 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 144233 entries, 0 to 144232\n",
      "Columns: 287 entries, TransactionID to DeviceType_mobile\n",
      "dtypes: float16(202), float32(25), int64(5), uint8(55)\n",
      "memory usage: 83.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(trainIdentityData.info())\n",
    "print(finalDataSet.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "increased-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.compat import v1 as tf_compat_v1\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def build_perceptron_model(in_dim: int, out_dim: int):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(512, activation='tanh', input_dim=in_dim))\n",
    "    model.add(keras.layers.Dense(136, activation='sigmoid'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    #model.add(keras.layers.Dropout(0.01))\n",
    "    model.add(keras.layers.Dense(out_dim, activation='softmax'))\n",
    "\n",
    "    adam = keras.optimizers.Adam(beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "#finalDataSet.head()\n",
    "#finalDataSet = finalDataSet.astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "robust-entrepreneur",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590540, 243)\n",
      "(590540,)\n",
      "Epoch 1/100\n",
      "4614/4614 [==============================] - 23s 5ms/step - loss: 0.1538 - accuracy: 0.9643\n",
      "Epoch 2/100\n",
      "4614/4614 [==============================] - 22s 5ms/step - loss: 0.1525 - accuracy: 0.9648\n",
      "Epoch 3/100\n",
      "4614/4614 [==============================] - 23s 5ms/step - loss: 0.1520 - accuracy: 0.9649\n",
      "Epoch 4/100\n",
      "4614/4614 [==============================] - 24s 5ms/step - loss: 0.1536 - accuracy: 0.9644 0s - loss: 0.1536 - accuracy: 0.96 - ETA: 0s - loss: 0.1\n",
      "Epoch 5/100\n",
      "4614/4614 [==============================] - 21s 5ms/step - loss: 0.1514 - accuracy: 0.9651\n",
      "Epoch 6/100\n",
      "4614/4614 [==============================] - 22s 5ms/step - loss: 0.1507 - accuracy: 0.9652\n",
      "Epoch 7/100\n",
      "4614/4614 [==============================] - 25s 5ms/step - loss: 0.1519 - accuracy: 0.9649\n",
      "Epoch 8/100\n",
      "4614/4614 [==============================] - 19s 4ms/step - loss: 0.1522 - accuracy: 0.9648\n",
      "Epoch 9/100\n",
      "4614/4614 [==============================] - 18s 4ms/step - loss: 0.1521 - accuracy: 0.9648\n",
      "Epoch 10/100\n",
      "4614/4614 [==============================] - 18s 4ms/step - loss: 0.1512 - accuracy: 0.9651\n",
      "Epoch 11/100\n",
      "4614/4614 [==============================] - 18s 4ms/step - loss: 0.1516 - accuracy: 0.9649\n",
      "Epoch 12/100\n",
      "4614/4614 [==============================] - 18s 4ms/step - loss: 0.1525 - accuracy: 0.9647 0s - loss: 0.1525 - accuracy: 0.\n",
      "Epoch 13/100\n",
      "4614/4614 [==============================] - 21s 4ms/step - loss: 0.1510 - accuracy: 0.9651\n",
      "Epoch 14/100\n",
      "4614/4614 [==============================] - 23s 5ms/step - loss: 0.1512 - accuracy: 0.9650\n",
      "Epoch 15/100\n",
      "4614/4614 [==============================] - 23s 5ms/step - loss: 0.1520 - accuracy: 0.9648\n",
      "Epoch 16/100\n",
      "4614/4614 [==============================] - 22s 5ms/step - loss: 0.1516 - accuracy: 0.9650\n",
      "Epoch 17/100\n",
      "4614/4614 [==============================] - 23s 5ms/step - loss: 0.1512 - accuracy: 0.9651\n",
      "Epoch 18/100\n",
      "4614/4614 [==============================] - 23s 5ms/step - loss: 0.1511 - accuracy: 0.9651\n",
      "Epoch 19/100\n",
      "4614/4614 [==============================] - 23s 5ms/step - loss: 0.1516 - accuracy: 0.9650\n",
      "Epoch 20/100\n",
      "4614/4614 [==============================] - 24s 5ms/step - loss: 0.1497 - accuracy: 0.9655\n",
      "Epoch 21/100\n",
      "4614/4614 [==============================] - 23s 5ms/step - loss: 0.1514 - accuracy: 0.9650\n",
      "Epoch 22/100\n",
      "4614/4614 [==============================] - 22s 5ms/step - loss: 0.1501 - accuracy: 0.9654\n",
      "Epoch 23/100\n",
      "4614/4614 [==============================] - 29s 6ms/step - loss: 0.1509 - accuracy: 0.9652\n"
     ]
    }
   ],
   "source": [
    "#print(finalDataSet.info())\n",
    "finalDataSet.shape\n",
    "\n",
    "#x_t = pd.read_csv('/Users/mike/ieee-fraud-detection/train_transaction.csv')\n",
    "#y_t = pd.read_csv('/Users/mike/ieee-fraud-detection/train_identity.csv')\n",
    "#y_t = pd.merge(left = x_t, right = y_t, on = \"TransactionID\")\n",
    "#y_t = x_t[\"isFraud\"]\n",
    "#trainData = pd.concat([trainTransactionData, trainIdentityData], axis = 1)\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "perceptron_model = build_perceptron_model(len(trainTransactionData.columns), 2)\n",
    "print(trainTransactionData.shape)\n",
    "print(y_train.shape)\n",
    "per = perceptron_model.fit(trainTransactionData, y_train, epochs=100, batch_size=128, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "inappropriate-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_test = perceptron_model.predict(testTransactionData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "numerical-germany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TransactionID  TransactionDT  TransactionAmt     card1     card2  \\\n",
      "count   5.066910e+05       506691.0   506691.000000  506691.0  506691.0   \n",
      "mean    3.916896e+06     26929936.0             NaN       NaN       NaN   \n",
      "std     1.462692e+05      4756507.0             NaN       NaN       NaN   \n",
      "min     3.663549e+06     18403224.0        0.018005    1001.0     100.0   \n",
      "25%     3.790222e+06     22771541.0       40.000000    6020.0     215.0   \n",
      "50%     3.916894e+06     27204658.0       67.937500    9800.0     363.0   \n",
      "75%     4.043566e+06     31348561.0      125.000000   14272.0     512.0   \n",
      "max     4.170239e+06     34214344.0    10272.000000   18400.0     600.0   \n",
      "\n",
      "          card3     card5      addr1     addr2     dist1  ...          M4_M1  \\\n",
      "count  506691.0  506691.0  506691.00  506691.0  506691.0  ...  506691.000000   \n",
      "mean        NaN       NaN        NaN       NaN       NaN  ...       0.087785   \n",
      "std         0.0       0.0        NaN       0.0       NaN  ...       0.282983   \n",
      "min       100.0     100.0     100.00      10.0       0.0  ...       0.000000   \n",
      "25%       150.0     166.0     205.00      87.0       8.0  ...       0.000000   \n",
      "50%       150.0     226.0     291.25      87.0       8.0  ...       0.000000   \n",
      "75%       150.0     226.0     327.00      87.0       8.0  ...       0.000000   \n",
      "max       232.0     237.0     540.00     102.0    8080.0  ...       1.000000   \n",
      "\n",
      "               M4_M2           M6_F           M6_T           M7_F  \\\n",
      "count  506691.000000  506691.000000  506691.000000  506691.000000   \n",
      "mean        0.124498       0.691775       0.308225       0.924129   \n",
      "std         0.330149       0.461761       0.461761       0.264791   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       1.000000   \n",
      "50%         0.000000       1.000000       0.000000       1.000000   \n",
      "75%         0.000000       1.000000       1.000000       1.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "                M7_T           M8_F           M8_T           M9_F  \\\n",
      "count  506691.000000  506691.000000  506691.000000  506691.000000   \n",
      "mean        0.075871       0.796152       0.203848       0.069881   \n",
      "std         0.264791       0.402858       0.402858       0.254946   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       1.000000       0.000000       0.000000   \n",
      "50%         0.000000       1.000000       0.000000       0.000000   \n",
      "75%         0.000000       1.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "                M9_T  \n",
      "count  506691.000000  \n",
      "mean        0.930119  \n",
      "std         0.254946  \n",
      "min         0.000000  \n",
      "25%         1.000000  \n",
      "50%         1.000000  \n",
      "75%         1.000000  \n",
      "max         1.000000  \n",
      "\n",
      "[8 rows x 243 columns]\n"
     ]
    }
   ],
   "source": [
    "print(testTransactionData.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-miniature",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
